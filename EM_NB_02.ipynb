{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EM_NB_02.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMXPcc54MhGrDsGa0cMKnAT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssvadla/Research_01/blob/main/EM_NB_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIS1NMTWF9WK"
      },
      "source": [
        "\n",
        "\n",
        "  \n",
        "# The code in this module is adapted from scikit-learn's Naive Bayes classifier.\n",
        "# The original code has been altered to implement the semi-supervised version of\n",
        "# Naive Bayes described in Section 5.3.1 of the following paper:\n",
        "\n",
        "# K. Nigam, A.K. McCallum, S. Thrun, T. Mitchell (2000). Text classification\n",
        "# from labeled and unlabeled documents using EM. Machine Learning 39(2-3),\n",
        "# pp. 103-134.\n",
        "\n",
        "#\n",
        "# Original copyright notice below:\n",
        "# Author: Vincent Michel <vincent.michel@inria.fr>\n",
        "#         Minor fixes by Fabian Pedregosa\n",
        "#         Amit Aides <amitibo@tx.technion.ac.il>\n",
        "#         Yehuda Finkelstein <yehudaf@tx.technion.ac.il>\n",
        "#         Lars Buitinck\n",
        "#         Jan Hendrik Metzen <jhm@informatik.uni-bremen.de>\n",
        "#         (parts based on earlier work by Mathieu Blondel)\n",
        "#\n",
        "# License: BSD 3 clause\n",
        "\n",
        "import numpy as np\n",
        "from scipy.sparse import issparse\n",
        "\n",
        "from sklearn.naive_bayes import _BaseDiscreteNB\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.utils import check_X_y, check_array\n",
        "from sklearn.utils.extmath import safe_sparse_dot\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "\n",
        "class MultinomialNBSS(_BaseDiscreteNB):\n",
        "    \"\"\"\n",
        "    Semi-supervised Naive Bayes classifier for multinomial models.  Unlabeled\n",
        "    data must be marked with -1.  In comparison to the standard scikit-learn\n",
        "    MultinomialNB classifier, the main differences are in the _count and fit\n",
        "    methods.\n",
        "    Parameters\n",
        "    ----------\n",
        "    alpha : float, optional (default=1.0)\n",
        "        Additive (Laplace/Lidstone) smoothing parameter\n",
        "        (0 for no smoothing).\n",
        "    beta : float, optional (default=1.0)\n",
        "        Weight applied to the contribution of the unlabeled data\n",
        "        (0 for no contribution).\n",
        "    fit_prior : boolean, optional (default=True)\n",
        "        Whether to learn class prior probabilities or not.\n",
        "        If false, a uniform prior will be used.\n",
        "    class_prior : array-like, size (n_classes,), optional (default=None)\n",
        "        Prior probabilities of the classes. If specified the priors are not\n",
        "        adjusted according to the data.\n",
        "    tol : float, optional (default=1e-3)\n",
        "        Tolerance for convergence of EM algorithm.\n",
        "    max_iter : int, optional (default=20)\n",
        "        Maximum number of iterations for EM algorithm.\n",
        "    verbose : boolean, optional (default=True)\n",
        "        Whether to output updates during the running of the EM algorithm.\n",
        "    Attributes\n",
        "    ----------\n",
        "    class_log_prior_ : array, shape (n_classes, )\n",
        "        Smoothed empirical log probability for each class.\n",
        "    intercept_ : array, shape (n_classes, )\n",
        "        Mirrors ``class_log_prior_`` for interpreting MultinomialNBSS\n",
        "        as a linear model.\n",
        "    feature_log_prob_ : array, shape (n_classes, n_features)\n",
        "        Empirical log probability of features\n",
        "        given a class, ``P(x_i|y)``.\n",
        "    coef_ : array, shape (n_classes, n_features)\n",
        "        Mirrors ``feature_log_prob_`` for interpreting MultinomialNBSS\n",
        "        as a linear model.\n",
        "    class_count_ : array, shape (n_classes,)\n",
        "        Number of samples encountered for each class during fitting. This\n",
        "        value is weighted by the sample weight when provided.\n",
        "    feature_count_ : array, shape (n_classes, n_features)\n",
        "        Number of samples encountered for each (class, feature)\n",
        "        during fitting. This value is weighted by the sample weight when\n",
        "        provided.\n",
        "    Examples\n",
        "    --------\n",
        "    >>> import numpy as np\n",
        "    >>> X = np.random.randint(5, size=(6, 100))\n",
        "    >>> y = np.array([1, 2, 3, 4, 5, 6])\n",
        "    >>> from semi_supervised_naive_bayes import MultinomialNBSS\n",
        "    >>> clf = MultinomialNBSS()\n",
        "    >>> clf.fit(X, y)\n",
        "    MultinomialNBSS(alpha=1.0, class_prior=None, fit_prior=True)\n",
        "    >>> print(clf.predict(X[2:3]))\n",
        "    [3]\n",
        "    Notes\n",
        "    -----\n",
        "    For the rationale behind the names `coef_` and `intercept_`, i.e.\n",
        "    naive Bayes as a linear classifier, see J. Rennie et al. (2003),\n",
        "    Tackling the poor assumptions of naive Bayes text classifiers, ICML.\n",
        "    References\n",
        "    ----------\n",
        "    C.D. Manning, P. Raghavan and H. Schuetze (2008). Introduction to\n",
        "    Information Retrieval. Cambridge University Press, pp. 234-265.\n",
        "    https://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html\n",
        "    K. Nigam, A.K. McCallum, S. Thrun, T. Mitchell (2000). Text classification\n",
        "    from labeled and unlabeled documents using EM. Machine Learning 39(2-3),\n",
        "    pp. 103-134.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, alpha=1.0, beta=1.0, fit_prior=True, class_prior=None,\n",
        "                 tol=1e-3, max_iter=20, verbose=True):\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.fit_prior = fit_prior\n",
        "        self.class_prior = class_prior\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def _count(self, X, Y, U_X=np.array([]), U_prob=np.array([])):\n",
        "        \"\"\"Count and smooth feature occurrences.\"\"\"\n",
        "        if np.any((X.data if issparse(X) else X) < 0):\n",
        "            raise ValueError(\"Input X must be non-negative\")\n",
        "\n",
        "        self.feature_count_ = safe_sparse_dot(Y.T, X)\n",
        "        self.class_count_ = Y.sum(axis=0)\n",
        "\n",
        "        if U_X.shape[0] > 0:\n",
        "            self.feature_count_ += self.beta*safe_sparse_dot(U_prob.T, U_X)\n",
        "            self.class_count_ += self.beta*U_prob.sum(axis=0)\n",
        "        else:\n",
        "            self.feature_count_ = safe_sparse_dot(Y.T, X)\n",
        "            self.class_count_ = Y.sum(axis=0)\n",
        "\n",
        "    def _update_feature_log_prob(self, alpha):\n",
        "        \"\"\"Apply smoothing to raw counts and recompute log probabilities\"\"\"\n",
        "        smoothed_fc = self.feature_count_ + alpha\n",
        "        smoothed_cc = smoothed_fc.sum(axis=1)\n",
        "\n",
        "        self.feature_log_prob_ = (np.log(smoothed_fc) -\n",
        "                                  np.log(smoothed_cc.reshape(-1, 1)))\n",
        "\n",
        "    def _joint_log_likelihood(self, X):\n",
        "        \"\"\"Calculate the posterior log probability of the samples X\"\"\"\n",
        "        check_is_fitted(self, \"classes_\")\n",
        "\n",
        "        X = check_array(X, accept_sparse='csr')\n",
        "        return (safe_sparse_dot(X, self.feature_log_prob_.T) +\n",
        "                self.class_log_prior_)\n",
        "\n",
        "    def partial_fit(self, X, y, classes=None, sample_weight=None):\n",
        "        \"\"\"A semi-supervised version of this method has not been implemented.\n",
        "        \"\"\"\n",
        "\n",
        "    def fit(self, X, y, sample_weight=None):\n",
        "        \"\"\"Fit semi-supervised Naive Bayes classifier according to X, y\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
        "            Training vectors, where n_samples is the number of samples and\n",
        "            n_features is the number of features.\n",
        "        y : array-like, shape = [n_samples]\n",
        "            Target values.  Unlabeled data must be marked with -1.\n",
        "        sample_weight : array-like, shape = [n_samples], (default=None)\n",
        "            Weights applied to individual samples (1. for unweighted).\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "        \"\"\"\n",
        "        X, y = check_X_y(X, y, 'csr')\n",
        "        _, n_features = X.shape\n",
        "        # Unlabeled data are marked with -1\n",
        "        unlabeled = np.flatnonzero(y == -1)\n",
        "        labeled = np.setdiff1d(np.arange(len(y)), unlabeled)\n",
        "\n",
        "        labelbin = LabelBinarizer()\n",
        "        Y = labelbin.fit_transform(y[labeled])\n",
        "        self.classes_ = labelbin.classes_\n",
        "        if Y.shape[1] == 1:\n",
        "            Y = np.concatenate((1 - Y, Y), axis=1)\n",
        "\n",
        "        # LabelBinarizer().fit_transform() returns arrays with dtype=np.int64.\n",
        "        # We convert it to np.float64 to support sample_weight consistently;\n",
        "        # this means we also don't have to cast X to floating point\n",
        "        Y = Y.astype(np.float64, copy=False)\n",
        "        if sample_weight is not None:\n",
        "            sample_weight = np.atleast_2d(sample_weight)\n",
        "            Y *= check_array(sample_weight).T\n",
        "\n",
        "        class_prior = self.class_prior\n",
        "\n",
        "        # Count raw events from data before updating the class log prior\n",
        "        # and feature log probas\n",
        "        n_effective_classes = Y.shape[1]\n",
        "\n",
        "        alpha = self._check_alpha()\n",
        "        self._count(X[labeled], Y)\n",
        "\n",
        "\n",
        "        self._update_feature_log_prob(alpha)\n",
        "        self._update_class_log_prior(class_prior=class_prior)\n",
        "        jll = self._joint_log_likelihood(X)\n",
        "        sum_jll = jll.sum()\n",
        "\n",
        "        # Run EM algorithm\n",
        "        if len(unlabeled) > 0:\n",
        "            self.num_iter = 0\n",
        "            pred = self.predict(X)\n",
        "            while self.num_iter < self.max_iter:\n",
        "                self.num_iter += 1\n",
        "                prev_sum_jll = sum_jll\n",
        "\n",
        "                # First, the E-step:\n",
        "                prob = self.predict_proba(X[unlabeled])\n",
        "\n",
        "                # Then, the M-step:\n",
        "                self._count(X[labeled], Y, X[unlabeled], prob)\n",
        "                self._update_feature_log_prob(self.beta)\n",
        "                self._update_class_log_prior(class_prior=class_prior)\n",
        "\n",
        "                jll = self._joint_log_likelihood(X)\n",
        "                sum_jll = jll.sum()\n",
        "                if self.verbose:\n",
        "                    print(\n",
        "                        'Step {}: jll = {:f}'.format(self.num_iter, sum_jll)\n",
        "                    )\n",
        "\n",
        "                if self.num_iter > 1 and prev_sum_jll - sum_jll < self.tol:\n",
        "                    break\n",
        "\n",
        "            if self.verbose:\n",
        "                end_text = 's.' if self.num_iter > 1 else '.'\n",
        "                print(\n",
        "                    'Optimization converged after {} '\n",
        "                    'iteration'.format(self.num_iter)\n",
        "                    + end_text\n",
        "                )\n",
        "\n",
        "        return self\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx59_t4gGDcl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "MJaX0B4lWLL7",
        "outputId": "b4726b7c-6585-4610-82eb-455f11109cea"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train1 = pd.read_csv('/content/drive/My Drive/Research/train_data1.csv')\n",
        "train2 = pd.read_csv('/content/drive/My Drive/Research/train_data2.csv')\n",
        "train3 = pd.read_csv('/content/drive/My Drive/Research/train_data3.csv')\n",
        "train4 = pd.read_csv('/content/drive/My Drive/Research/train_data4.csv')\n",
        "train5 = pd.read_csv('/content/drive/My Drive/Research/train_data5.csv')\n",
        "train6 = pd.read_csv('/content/drive/My Drive/Research/train_data6.csv')\n",
        "train7 = pd.read_csv('/content/drive/My Drive/Research/train_data7.csv')\n",
        "train8 = pd.read_csv('/content/drive/My Drive/Research/train_data8.csv')\n",
        "train9 = pd.read_csv('/content/drive/My Drive/Research/train_data9.csv')\n",
        "train10 = pd.read_csv('/content/drive/My Drive/Research/train_data10.csv')\n",
        "train_highKappa = pd.read_csv('/content/drive/My Drive/Research/train_data_highkappa.csv')\n",
        "train1.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>659</td>\n",
              "      <td>Appellant had stated to the officers that she ...</td>\n",
              "      <td>Invalid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3456</td>\n",
              "      <td>We shall discuss the facts more fully in conne...</td>\n",
              "      <td>Others</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2043</td>\n",
              "      <td>â€œPerjury is a false statement, either writte...</td>\n",
              "      <td>Invalid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3344</td>\n",
              "      <td>The offense is felony theft by false pretext; ...</td>\n",
              "      <td>Issue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3231</td>\n",
              "      <td>Numerous contentions urging the commission of ...</td>\n",
              "      <td>Issue</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                           Sentence   Target\n",
              "0         659  Appellant had stated to the officers that she ...  Invalid\n",
              "1        3456  We shall discuss the facts more fully in conne...   Others\n",
              "2        2043  â€œPerjury is a false statement, either writte...  Invalid\n",
              "3        3344  The offense is felony theft by false pretext; ...    Issue\n",
              "4        3231  Numerous contentions urging the commission of ...    Issue"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OnjMWRLePrW"
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c13Q_U4xOVv7"
      },
      "source": [
        "train = train1\n",
        "train_list = [train2,train3,train4,train5,train6,train7,train8,train9,train10,train_highKappa]\n",
        "for i in train_list:\n",
        "  #print(i)\n",
        "  train = train.append(i)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vzqrFjJK-SB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7a51043-0e38-4ce6-ebf8-80c3ca21cd72"
      },
      "source": [
        "train.sort_values(\"Sentence\", inplace = True)\n",
        "print(len(train))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGhA6QWYLoUe"
      },
      "source": [
        " new_train = train.drop_duplicates(subset =\"Sentence\")\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbPp_HOCRuCe"
      },
      "source": [
        "train = new_train"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L26kh03-L1Ws",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "456c1625-3832-43ba-d60a-adba61803aed"
      },
      "source": [
        "train['Target'].unique()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Invalid', 'Rule/Law/Holding', 'Facts', 'Analysis', 'Others',\n",
              "       'Conclusion', 'Issue'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxDI4OqrKdtj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49c48d23-43e7-4b7c-c72c-0cf835ce38f2"
      },
      "source": [
        "train['Target']=train['Target'].replace(['Others'],'Invalid')\n",
        "train['Target'].unique()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Invalid', 'Rule/Law/Holding', 'Facts', 'Analysis', 'Conclusion',\n",
              "       'Issue'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRe3cCJDRTY4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "283e5f81-9f0e-42c5-8361-11fa87d94bf3"
      },
      "source": [
        "#cleaning\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stopword=nltk.corpus.stopwords.words('english')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wl= WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text):\n",
        "  text=\"\".join([word.lower() for word in text if word not in string.punctuation])\n",
        "  tokens = re.split('\\W+',text)\n",
        "  text = [wl.lemmatize(word) for word in tokens if word not in stopword]\n",
        "  return text"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcB5PThsRZPa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfb981db-505a-4182-da03-42df2da930c2"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vect = TfidfVectorizer(analyzer = clean_text)\n",
        "X_tfidf = tfidf_vect.fit_transform(train['Sentence'])\n",
        "print(X_tfidf.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4416, 7374)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erVH3lWMRdUu"
      },
      "source": [
        "test = pd.read_csv(r'/content/drive/My Drive/Research/test_data.csv')\n",
        "\n",
        "test['Target']=test['Target'].replace(['Others'],'Invalid')\n",
        "test['Sentence'] = test['Sentence'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
        "test['Sentence'] = test['Sentence'].str.replace('[^\\w\\s]','')\n",
        "from nltk.corpus import stopwords\n",
        "words = stopwords.words('english')\n",
        "test['Sentence'] = test['Sentence'].apply(lambda x: \" \".join(x for x in x.split() if x not in words))\n",
        "t_p = tfidf_vect.transform(test['Sentence'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "626i_0gkef3W",
        "outputId": "1e8974b7-d2a9-412c-897f-fab6f8c382dc"
      },
      "source": [
        "\n",
        "unlabel = pd.read_csv(r'/content/drive/My Drive/Research/Unlabeled_data.csv')\n",
        "#unlabel.head()\n",
        "\n",
        "del unlabel['Complete']\n",
        "del unlabel['Unnamed: 0']\n",
        "\n",
        "unlabel['text'] = unlabel['text'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
        "unlabel['text'] = unlabel['text'].str.replace('[^\\w\\s]','')\n",
        "from nltk.corpus import stopwords\n",
        "words = stopwords.words('english')\n",
        "unlabel['text'] = unlabel['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in words))\n",
        "\n",
        "\n",
        "from textblob import TextBlob\n",
        "from textblob import Word\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "unlabel['text'] = unlabel['text'].apply(lambda x: TextBlob(x).words)\n",
        "unlabel['text'] = unlabel['text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x]))\n",
        "\n",
        "unlabel_1 = unlabel.loc[:500]\n",
        "\n",
        "\n",
        "def index_reset(unlabel_2):\n",
        "  unlabel_2.reset_index(inplace=True)\n",
        "  del unlabel_2['index']\n",
        "  #print(unlabel_2.head())\n",
        "  return unlabel_2\n",
        "\n",
        "unlabel_1 = index_reset(unlabel_1)\n",
        "unlabel_1_copy = unlabel_1\n",
        "\n",
        "\n",
        "\n",
        "x_un1 = tfidf_vect.transform(unlabel_1['text'])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2soJIWOn8l7"
      },
      "source": [
        "classifier = MultinomialNBSS()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijGoqt7Ms3oE",
        "outputId": "a23c00cb-f7c6-4c80-ba86-3ba05fa48f20"
      },
      "source": [
        "classifier.fit(X_tfidf,train['Target'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNBSS(alpha=1.0, beta=1.0, class_prior=None, fit_prior=True,\n",
              "                max_iter=20, tol=0.001, verbose=True)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYWzNH6StADQ",
        "outputId": "32973fe1-81d8-4322-a500-80ea581cc48c"
      },
      "source": [
        "print(classifier.predict(t_p))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Invalid'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Rule/Law/Holding'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Invalid' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Analysis' 'Conclusion' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Invalid' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Analysis'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Analysis' 'Facts' 'Facts' 'Facts' 'Facts' 'Invalid' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Invalid' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Invalid' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Conclusion' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Invalid' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Conclusion' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Invalid' 'Facts' 'Facts' 'Invalid' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Analysis' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Invalid' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Analysis' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Analysis' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Analysis' 'Invalid'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Analysis' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Analysis' 'Invalid' 'Facts' 'Analysis' 'Facts' 'Facts' 'Facts'\n",
            " 'Rule/Law/Holding' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Invalid' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Invalid'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Invalid' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Analysis' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Analysis'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Analysis' 'Facts' 'Facts' 'Facts' 'Invalid' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Analysis' 'Facts'\n",
            " 'Invalid' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Analysis'\n",
            " 'Facts' 'Facts' 'Facts' 'Invalid' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Invalid' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Analysis'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Conclusion' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Analysis' 'Invalid' 'Facts' 'Facts' 'Facts' 'Facts' 'Analysis'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Analysis'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Rule/Law/Holding'\n",
            " 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Facts' 'Invalid'\n",
            " 'Facts' 'Facts' 'Analysis' 'Facts' 'Facts' 'Facts' 'Facts' 'Invalid'\n",
            " 'Facts' 'Analysis' 'Facts' 'Facts']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1d2rVg4tLS6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8feE3QTehJTr",
        "outputId": "5331ae94-f342-4c24-c4a3-8d0dda56ebf3"
      },
      "source": [
        "unlabel_1['Target']=-1"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8ePmhB9hLSw",
        "outputId": "125ae63c-f8d6-4ea1-b05c-129fe2d01095"
      },
      "source": [
        "import numpy as np\n",
        "np.unique(unlabel_1['Target'])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIuBhhErhiuQ"
      },
      "source": [
        "train = train.rename(columns={'Sentence':'text'})"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZdoHrPBi9VC"
      },
      "source": [
        " from sklearn.preprocessing import LabelEncoder\n",
        " train['Target']= LabelEncoder().fit_transform(train['Target'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjwNzU-efKei",
        "outputId": "cbcfd318-11f2-4c72-9cf7-9d6e898ae6ac"
      },
      "source": [
        "train_and_unlabel =  pd.concat([train,unlabel_1])\n",
        "print(len(train))\n",
        "print(len(unlabel_1))\n",
        "print(len(train_and_unlabel))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4416\n",
            "501\n",
            "4917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-53aEmQyj0gW"
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "N0mETRPJhGH-",
        "outputId": "d12329dd-b06c-418f-e55f-455414e2a70f"
      },
      "source": [
        "train_and_unlabel.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1364</th>\n",
              "      <td>239.0</td>\n",
              "      <td>\"(I)n the First Amendment area 'government may...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1833</th>\n",
              "      <td>185.0</td>\n",
              "      <td>\"... that nowhere in the statute was it stated...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2431</th>\n",
              "      <td>415.0</td>\n",
              "      <td>\"Although a statute may be neither vague, over...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2245</th>\n",
              "      <td>416.0</td>\n",
              "      <td>\"For even when pursuing a legitimate interest,...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1561</th>\n",
              "      <td>25.0</td>\n",
              "      <td>\"If an indictment has been found or accusation...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0                                               text  Target\n",
              "1364       239.0  \"(I)n the First Amendment area 'government may...       3\n",
              "1833       185.0  \"... that nowhere in the statute was it stated...       3\n",
              "2431       415.0  \"Although a statute may be neither vague, over...       5\n",
              "2245       416.0  \"For even when pursuing a legitimate interest,...       5\n",
              "1561        25.0  \"If an indictment has been found or accusation...       2"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTRNFqC3h89e"
      },
      "source": [
        "\n",
        "train_and_unlabel.reset_index(inplace=True)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ln6ZNw3vjnD3",
        "outputId": "32b7c4ac-38db-4622-be7d-cf8b94dbdc5f"
      },
      "source": [
        "train_and_unlabel.columns"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['index', 'Unnamed: 0', 'text', 'Target'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfILrO0BjRW0"
      },
      "source": [
        "del train_and_unlabel['index']\n",
        "del train_and_unlabel['Unnamed: 0']"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "NdPDaRmvjfsZ",
        "outputId": "a0f9439b-2eb8-4cf4-950c-81983cac42ab"
      },
      "source": [
        "train_and_unlabel.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"(I)n the First Amendment area 'government may...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"... that nowhere in the statute was it stated...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"Although a statute may be neither vague, over...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"For even when pursuing a legitimate interest,...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"If an indictment has been found or accusation...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  Target\n",
              "0  \"(I)n the First Amendment area 'government may...       3\n",
              "1  \"... that nowhere in the statute was it stated...       3\n",
              "2  \"Although a statute may be neither vague, over...       5\n",
              "3  \"For even when pursuing a legitimate interest,...       5\n",
              "4  \"If an indictment has been found or accusation...       2"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "fTGbCJzFiAj4",
        "outputId": "d1cde888-917b-4969-90c0-81fb586b4755"
      },
      "source": [
        "train_and_unlabel.tail()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4912</th>\n",
              "      <td>time continuance partnership mr winn jack stal...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4913</th>\n",
              "      <td>correspondence appellant went coleman county s...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4914</th>\n",
              "      <td>appellant contention stock sold winn named pri...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4915</th>\n",
              "      <td>mr winns contention stock delivered appellant ...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4916</th>\n",
              "      <td>title stock passed appellant would guilty embe...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  Target\n",
              "4912  time continuance partnership mr winn jack stal...      -1\n",
              "4913  correspondence appellant went coleman county s...      -1\n",
              "4914  appellant contention stock sold winn named pri...      -1\n",
              "4915  mr winns contention stock delivered appellant ...      -1\n",
              "4916  title stock passed appellant would guilty embe...      -1"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hhg0ZRtlhAtX"
      },
      "source": [
        "train_and_unlabel_vect = tfidf_vect.transform(train_and_unlabel['text'])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI6NV1Fbh_5a"
      },
      "source": [
        "train_and_unlabel_vect_df=pd.DataFrame(train_and_unlabel_vect.toarray())\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01mdjAQ8mTSL",
        "outputId": "04bcd08b-b524-4a14-de6a-9d452d15197f"
      },
      "source": [
        "train_and_unlabel_vect_df.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4917, 7374)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrwUgvImupbX"
      },
      "source": [
        "classifier = MultinomialNBSS()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8VWxU4uulJV",
        "outputId": "b68ea6a1-e1e9-47a4-8888-c9b1366fec58"
      },
      "source": [
        "classifier.fit(train_and_unlabel_vect_df, train_and_unlabel['Target'])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: jll = -863064.748069\n",
            "Step 2: jll = -863710.698838\n",
            "Step 3: jll = -863876.562964\n",
            "Step 4: jll = -863927.697659\n",
            "Step 5: jll = -863945.467258\n",
            "Step 6: jll = -863952.127077\n",
            "Step 7: jll = -863954.756179\n",
            "Step 8: jll = -863955.835135\n",
            "Step 9: jll = -863956.291815\n",
            "Step 10: jll = -863956.490150\n",
            "Step 11: jll = -863956.578213\n",
            "Step 12: jll = -863956.618076\n",
            "Step 13: jll = -863956.636429\n",
            "Step 14: jll = -863956.645005\n",
            "Step 15: jll = -863956.649063\n",
            "Step 16: jll = -863956.651005\n",
            "Step 17: jll = -863956.651943\n",
            "Optimization converged after 17 iterations.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNBSS(alpha=1.0, beta=1.0, class_prior=None, fit_prior=True,\n",
              "                max_iter=20, tol=0.001, verbose=True)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBCDjwm5ur6Z"
      },
      "source": [
        "test_pred = classifier.predict(t_p)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdVLHFE6u2iV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptwbMbMqmlwC"
      },
      "source": [
        "#test_pred = gnb_classifier.predict(t_p.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jfs5wgHum9MJ",
        "outputId": "570ab517-edd5-49e3-f26b-2e11b5ca9082"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "test['Target']= LabelEncoder().fit_transform(test['Target'])\n",
        "classification_report_test = classification_report(test['Target'],test_pred,digits=4)\n",
        "print(classification_report_test)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4000    0.0779    0.1304        77\n",
            "           1     1.0000    0.1154    0.2069        26\n",
            "           2     0.5485    0.9963    0.7074       267\n",
            "           3     0.8125    0.1566    0.2626        83\n",
            "           4     0.0000    0.0000    0.0000        34\n",
            "           5     0.5000    0.0294    0.0556        34\n",
            "\n",
            "    accuracy                         0.5547       521\n",
            "   macro avg     0.5435    0.2293    0.2272       521\n",
            "weighted avg     0.5522    0.5547    0.4376       521\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y0-z7jVvJNc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}