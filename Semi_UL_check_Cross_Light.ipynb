{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semi_UL_check_Cross_Light.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMAM4AOhaTwZNE8thAgXKVx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssvadla/Research_01/blob/main/Semi_UL_check_Cross_Light.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oCG1ssyp86A"
      },
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import metrics\n",
        "\n",
        "f1_score_array = []\n",
        "unlabel_size_array = []\n",
        "train_data_size_array = []\n",
        "total_train_array = []\n",
        "validation_f1_score_array =[]\n",
        "def Training_UL_RF(unlabel_size,Threshold):\n",
        "    \n",
        "    import pandas as pd\n",
        "    from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "    train1 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data1.csv')\n",
        "    train2 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data2.csv')\n",
        "    train3 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data3.csv')\n",
        "    train4 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data4.csv')\n",
        "    train5 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data5.csv')\n",
        "    train6 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data6.csv')\n",
        "    train7 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data7.csv')\n",
        "    train8 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data8.csv')\n",
        "    train9 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data9.csv')\n",
        "    train10 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data10.csv')\n",
        "    train_highKappa = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data_highkappa.csv')\n",
        "\n",
        "    #train1.head()\n",
        "    train = train1\n",
        "    train_list = [train2,train3,train4,train5,train6,train7,train8,train9,train10,train_highKappa]\n",
        "    for i in train_list:\n",
        "      print(i)\n",
        "      train = train.append(i)\n",
        "\n",
        "    unlabel_size = unlabel_size\n",
        "    Threshold=Threshold\n",
        "    train.sort_values(\"Sentence\", inplace = True)\n",
        "    print(len(train))\n",
        "\n",
        "    train = train.drop_duplicates(subset =\"Sentence\")\n",
        "\n",
        "    train['Target'].unique()\n",
        "\n",
        "\n",
        "    train['Target']=train['Target'].replace(['Others'],'Invalid')\n",
        "    train['Target'].unique()\n",
        "\n",
        "\n",
        "\n",
        "    #cleaning\n",
        "    import nltk\n",
        "    import re\n",
        "    import string\n",
        "    nltk.download('stopwords')\n",
        "    nltk.download('wordnet')\n",
        "    stopword=nltk.corpus.stopwords.words('english')\n",
        "    from nltk.stem import WordNetLemmatizer\n",
        "    wl= WordNetLemmatizer()\n",
        "\n",
        "    def clean_text(text):\n",
        "      text=\"\".join([word.lower() for word in text if word not in string.punctuation])\n",
        "      tokens = re.split('\\W+',text)\n",
        "      text = [wl.lemmatize(word) for word in tokens if word not in stopword]\n",
        "      return text\n",
        "\n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "    tfidf_vect = TfidfVectorizer(analyzer = clean_text)\n",
        "    X_tfidf = tfidf_vect.fit_transform(train['Sentence'])\n",
        "    print(X_tfidf.shape)\n",
        "\n",
        "    test = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\test_data.csv')\n",
        "    test['Target']=test['Target'].replace(['Others'],'Invalid')\n",
        "    test['Sentence'] = test['Sentence'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
        "    test['Sentence'] = test['Sentence'].str.replace('[^\\w\\s]','')\n",
        "    from nltk.corpus import stopwords\n",
        "    words = stopwords.words('english')\n",
        "    test['Sentence'] = test['Sentence'].apply(lambda x: \" \".join(x for x in x.split() if x not in words))\n",
        "    t_p = tfidf_vect.transform(test['Sentence'])\n",
        "\n",
        "    import numpy as np\n",
        "    import statistics\n",
        "    from sklearn.datasets import make_classification\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from sklearn.pipeline import make_pipeline\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    from sklearn.metrics import average_precision_score\n",
        "    from sklearn.metrics import precision_score\n",
        "    from sklearn.metrics import recall_score\n",
        "    from sklearn.metrics import f1_score\n",
        "    from sklearn.metrics import cohen_kappa_score\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "\n",
        "    X, y = make_classification(random_state=1)\n",
        "\n",
        "    X_train, x_val, Y_train, y_val = train_test_split(X_tfidf,train['Target'],test_size=0.20,random_state=42)\n",
        "\n",
        "    classifier = lgb.LGBMClassifier()\n",
        "    classifier.fit(X_train, Y_train)\n",
        "    y_pred = classifier.predict(x_val)\n",
        "    #print(np.unique(y_pred))\n",
        "    #print(type(y_pred))\n",
        "\n",
        "    Accuracy_score = accuracy_score(y_val,y_pred)\n",
        "    test_pred = classifier.predict(t_p)\n",
        "    acc_test = accuracy_score(test['Target'], test_pred)\n",
        "    print('Accuracy test data', acc_test)\n",
        "    classification_report_supervised = classification_report(test['Target'], test_pred, digits = 4)\n",
        "\n",
        "    print(classification_report_supervised)\n",
        "    matrix = confusion_matrix(y_val, y_pred)\n",
        "    print(matrix)\n",
        "\n",
        "\n",
        "    unlabel = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Unlabeled_data.csv')\n",
        "    #unlabel.head()\n",
        "\n",
        "    del unlabel['Complete']\n",
        "    del unlabel['Unnamed: 0']\n",
        "\n",
        "    unlabel['text'] = unlabel['text'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
        "    unlabel['text'] = unlabel['text'].str.replace('[^\\w\\s]','')\n",
        "    from nltk.corpus import stopwords\n",
        "    words = stopwords.words('english')\n",
        "    unlabel['text'] = unlabel['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in words))\n",
        "\n",
        "\n",
        "    from textblob import TextBlob\n",
        "    from textblob import Word\n",
        "    nltk.download('wordnet')\n",
        "    nltk.download('punkt')\n",
        "    unlabel['text'] = unlabel['text'].apply(lambda x: TextBlob(x).words)\n",
        "    unlabel['text'] = unlabel['text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x]))\n",
        "\n",
        "    unlabel_1 = unlabel.loc[:unlabel_size]\n",
        "\n",
        "    def index_reset(unlabel_2):\n",
        "      unlabel_2.reset_index(inplace=True)\n",
        "      del unlabel_2['index']\n",
        "      #print(unlabel_2.head())\n",
        "      return unlabel_2\n",
        "\n",
        "    unlabel_1 = index_reset(unlabel_1)\n",
        "\n",
        "    x_un1 = tfidf_vect.transform(unlabel_1['text'])\n",
        "\n",
        "    x_un1.shape\n",
        "    pred_unlabel_1 = classifier.predict_proba(x_un1)\n",
        "    pred_unlabel_1\n",
        "\n",
        "    x_un1.shape\n",
        "\n",
        "    import numpy as np\n",
        "    pos=[]\n",
        "    large=[]\n",
        "    ind = []\n",
        "    i=0\n",
        "    for j in pred_unlabel_1:\n",
        "      if max(j)> Threshold:\n",
        "        ind.append(np.argmax(j))\n",
        "        large.append(max(j))\n",
        "        pos.append(i)\n",
        "      i+=1\n",
        "\n",
        "\n",
        "    print(ind)\n",
        "    print(large)\n",
        "    print(pos)\n",
        "    print(type(pos))\n",
        "    print(len(ind))\n",
        "    print(len(large))\n",
        "    print(len(pos))\n",
        "\n",
        "    unlabel_1 = unlabel_1.loc[pos,:]\n",
        "    train_data_size = len(unlabel_1)\n",
        "    print(len(unlabel_1))\n",
        "    #unlabel_1.head()\n",
        "\n",
        "    class_x_un1 = tfidf_vect.transform(unlabel_1['text'])\n",
        "\n",
        "    class_x_un1.shape\n",
        "\n",
        "\n",
        "    class_pred_unlabel_1 = classifier.predict(class_x_un1)\n",
        "    class_pred_unlabel_1\n",
        "\n",
        "\n",
        "    unlabel_1['Target']=class_pred_unlabel_1\n",
        "    #unlabel_1.head()\n",
        "    \n",
        "    train = train.rename(columns={'Sentence':'text'})\n",
        "    frame_1 = [train,unlabel_1]\n",
        "    train_1 = pd.concat(frame_1)\n",
        "    \n",
        "    print(\"#######3train len\",len(train))\n",
        "    print(\"UL \",len(unlabel_1))\n",
        "    print(\"train_1\",len(train_1))\n",
        "    total_train = len(train_1)\n",
        "    del train\n",
        "    del unlabel_1\n",
        "    del unlabel\n",
        "\n",
        "\n",
        "\n",
        "    from sklearn.metrics import classification_report\n",
        "    from sklearn import svm\n",
        "\n",
        "    x_train_1 = tfidf_vect.transform(train_1['text'])\n",
        "    x_train_1.shape\n",
        "    X_train, x_val, Y_train, y_val = train_test_split(x_train_1,train_1['Target'],test_size=0.25,random_state=2)\n",
        "    classifier_1 = lgb.LGBMClassifier()\n",
        "    classifier_1.fit(X_train, Y_train)\n",
        "    y_pred = classifier_1.predict(x_val)\n",
        "    Accuracy_score = accuracy_score(y_val, y_pred)\n",
        "\n",
        "    print('Validation ------- Accuracy_score: %f' % Accuracy_score)\n",
        "    cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "    scores_f1 = cross_val_score(classifier_1,x_val ,y_val, scoring = 'f1_weighted', cv=cv, n_jobs=-1).mean()\n",
        "    #avg_scores = statistics.mean(scores) \n",
        "    print(\"@@@@@@@cross validation scores \",scores_f1)\n",
        "    \n",
        "    scores_acc = cross_val_score(classifier_1,x_val ,y_val, scoring = 'accuracy', cv=cv, n_jobs=-1).mean()\n",
        "    #avg_scores = statistics.mean(scores) \n",
        "\n",
        "    print(\"@@@@@@@cross validation scores \",scores_acc)\n",
        "    scores_pre = cross_val_score(classifier_1,x_val ,y_val, scoring = 'precision', cv=cv, n_jobs=-1).mean()\n",
        "    scores_recall = cross_val_score(classifier_1,x_val ,y_val, scoring = 'recall', cv=cv, n_jobs=-1).mean()\n",
        " \n",
        "\n",
        "\n",
        "    test_pred = classifier_1.predict(t_p)\n",
        "    acc_test = accuracy_score(test['Target'],test_pred)\n",
        "    print('Test ------Semi Supervised Accuracy score ', acc_test)\n",
        "    matrix = confusion_matrix( y_val,y_pred)\n",
        "    print(matrix)\n",
        "    print(\"---------validation--------------\")\n",
        "    print(classification_report(y_val,y_pred,digits=4))\n",
        "    print(\"----------test---------------------\")\n",
        "    classification_report_semi_supervised = classification_report(test['Target'],test_pred, digits=4)\n",
        "    f1_Score_metric = f1_score(test['Target'],test_pred,average='weighted')\n",
        "    \n",
        "    print(classification_report_semi_supervised)\n",
        "    print(f1_Score_metric)\n",
        "\n",
        "\n",
        "    # Write line to file\n",
        "\n",
        "    with open(r'C:\\Users\\iia\\Documents\\Supriya\\Results_3\\SS_UL_Light.txt', 'a') as writefile:\n",
        "      writefile.write(\"\\n\")\n",
        "      writefile.write(\" RF \")\n",
        "      writefile.write(\"\\n\")\n",
        "      writefile.write(\"Threshold = \")\n",
        "      writefile.write(str(Threshold))\n",
        "      writefile.write(\"\\n\")\n",
        "      writefile.write(\"unlabel size  = \")\n",
        "      writefile.write(str(unlabel_size))\n",
        "      writefile.write(\"\\n\")\n",
        "      writefile.write(\"train data size  = \")\n",
        "      writefile.write(str(train_data_size))\n",
        "      writefile.write(\"\\n\")\n",
        "      writefile.write(\"total_train = \")  \n",
        "      writefile.write(str(total_train))\n",
        "      writefile.write(\"\\n\")  \n",
        "      writefile.write(\"Supervised Resutls on Test Data\")\n",
        "      writefile.write(\"\\n\")\n",
        "      writefile.write(classification_report_supervised)\n",
        "      writefile.write(\"\\n\")\n",
        "      writefile.write(\"Semi Supervised Resutls on Test Data\")\n",
        "      writefile.write(\"\\n\")\n",
        "      writefile.write(classification_report_semi_supervised)\n",
        "      writefile.write(\"Semi Supervised F1score on Test Data\")\n",
        "      writefile.write(\"\\n\")\n",
        "      writefile.write(\" Test f1 score test \")\n",
        "      writefile.write(str(f1_Score_metric))\n",
        "      writefile.write(\"\\n\")\n",
        "      writefile.write(\"training accuracy \")  \n",
        "      writefile.write(str(scores_acc))\n",
        "      writefile.write(\"\\n\")   \n",
        "      writefile.write(\"training precision \") \n",
        "      writefile.write(str(scores_pre))  \n",
        "      writefile.write(\"\\n\")   \n",
        "      writefile.write(\"training recall \") \n",
        "      writefile.write(str(scores_recall))\n",
        "      writefile.write(\"\\n\")   \n",
        "      writefile.write(\"training f1 score \")\n",
        "      writefile.write(str(scores_f1))  \n",
        "      writefile.write(\"\\n\") \n",
        "\n",
        "\n",
        "    print(\"Done\")\n",
        "    f1_score_array.append(f1_Score_metric)\n",
        "    validation_f1_score_array.append(scores_f1)\n",
        "    unlabel_size_array.append(unlabel_size)\n",
        "    train_data_size_array.append(train_data_size)\n",
        "    total_train_array.append(total_train)\n",
        "    \n",
        "    return f1_score_array,unlabel_size_array,train_data_size_array,validation_f1_score_array,total_train_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r2JJjn2qVwE"
      },
      "source": [
        "unlabel_size_list = range(1000,500000,5000)\n",
        "unlabel_size_list[5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViMYFTBuqeHn"
      },
      "source": [
        "len(unlabel_size_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee2wDmYpqhd-"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "Threshold = 0.99\n",
        "iteration = 0 \n",
        "\n",
        "for size in unlabel_size_list:\n",
        "    print(\"iteration\",iteration)\n",
        "    print(\"size of the data got into \", size )\n",
        "    op_f1_score,op_unlabel_size,op_train_data_size,op_val_f1_array,op_total_train_array = Training_UL_RF(size,Threshold)\n",
        "    iteration = iteration + 1\n",
        "    \n",
        "with open(r'C:\\Users\\iia\\Documents\\Supriya\\Results_3\\SS_UL_Light_variables.txt', 'a') as writefile:\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\" RF \")\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\"op_f1_score\")\n",
        "    writefile.write(str(op_f1_score))\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\"op_unlabel_size\")\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(str(op_unlabel_size))\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\"op_train_data_size\")\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(str(op_train_data_size))\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\"op_val_f1_array\")\n",
        "    writefile.write(str(op_val_f1_array))\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\"op_total_train_array = \")\n",
        "    writefile.write(str(op_total_train_array))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}